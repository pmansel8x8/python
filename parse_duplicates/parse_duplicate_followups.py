"""
This python script will scan a CSV file that should contain data about
duplicate followups. The format of the file should be:

"ID","ID_1","EMAIL_HASH","C","VALUE","CASE_STATUS"
3189088,4187180,"+JAu0yZko6rkW8EJX1IUkg==",2,"Open","Updated"
3189088,4187184,"+JAu0yZko6rkW8EJX1IUkg==",2,"Open","Updated"
...

Where 
 * ID is the CASE ID
 * ID_1 is the FOLLOWUP ID

This data can be generated by the following SQL query:

SELECT
    cases.id,
    followups.id,
    b.email_hash,
    b.c,
    w.value,
    decode(nvl(cases.last_activity, cases.open_date), cases.open_date, 'Not updated', 'Updated') case_status
FROM
         (
        SELECT
            a.*,
            COUNT(*)
            OVER(PARTITION BY email_hash) c
        FROM
            (
                SELECT
                    fo.id                                      AS followupid,
                    wpjadmin.blob_md5_checksum(f.file_content) AS email_hash
                FROM
                         tenant0099.followups fo
                    JOIN tenant0099.cases       ca ON ( ca.id = fo.caseid )
                    JOIN tenant0099.attachments a ON ( a.followupid = fo.id )
                    JOIN tenant0099.files       f ON ( f.id = a.fileid )
                WHERE
                    fo.create_date BETWEEN TO_DATE('2021-12-13 00:00:00', 'YYYY-MM-DD HH24:MI:SS') AND TO_DATE('2021-12-15 23:59:59',
                    'YYYY-MM-DD HH24:MI:SS')
                    AND a.file_name = 'message_source.txt'
            ) a
    ) b
    JOIN tenant0099.followups     followups ON ( b.followupid = followups.id )
    JOIN tenant0099.cases         cases ON ( followups.caseid = cases.id )
    JOIN tenant0099.wpj_picklists w ON ( cases.cf_status.wpj_picklist = w.id )
WHERE
    b.c > 1
ORDER BY
    b.email_hash,
    cases.id,
    followups.id;

The duplicate followups will be scanned, and all copies except the oldest one
will be deleted.
"""
import csv
import time
from collections import defaultdict
from rich import print
from rich.live import Live
from rich.panel import Panel
from rich.progress import track
from rich.table import Table


def generate_table(row: list) -> Table:
    """Make a new table."""
    table = Table()
    table.add_column("Hash")
    table.add_column("Case Id")
    table.add_column("Followup Id")
    table.add_column("# copies")
    table.add_column("Status")

    if len(row) > 0:
        table.add_row(
            f"{row[2]}",
            f"{row[0]}",
            f"{row[1]}",
            f"{row[3]}",
            "[red]Updated" if row[5] == "Updated" else "[green]Not updated",
        )
    return table


def parse_csv_file(filename: str) -> defaultdict:
    """
    Parse CSV file, and store duplicates in a dictionary where
    the key is the email hash, and the value is a list of CSV records
    that share the same hash
    """
    # ['CASEID', 'FOLLOWUPID', 'EMAIL_HASH', 'C', 'VALUE', 'CASE_STATUS']

    followups_by_hash = defaultdict(list)
    with open(filename, "r") as csvfile:
        csvreader = csv.reader(csvfile)

        # Skip header
        next(csvreader)

        with Live(generate_table([]), refresh_per_second=100) as live:
            for row in csvreader:
                followups_by_hash[row[2]].append(row)
                live.update(generate_table(row))

                # Remove this if you want speed over fanccy display
                time.sleep(0.01)

    return followups_by_hash


def generate_list_of_ids_to_delete(followups_by_hash: defaultdict) -> list:
    """
    For each group of duplicates, extract the IDs of the followups that
    will be deleted (all but the oldest one). Returns a list of all the IDs
    to delete.
    """
    followups_to_delete: list = []
    for item in track(followups_by_hash.items(), description="Processing..."):
        email_followups: list = item[1]
        for email_followup in email_followups[1:]:
            followups_to_delete.append(email_followup[1])
            # Remove this if you want speed over fanccy display
            time.sleep(0.01)

    print(f"Found {len(followups_to_delete)} followups to delete")
    return followups_to_delete


def build_delete_statement(tenant: str, table: str, followups_to_delete: list) -> str:
    """
    Formats the DELETE statement using the list of followup IDs
    that should be deleted.
    """
    followup_id_list = ""
    for followupid in followups_to_delete[:-1]:
        followup_id_list += followupid + ","

    followup_id_list += followups_to_delete[-1]
    return f"[red]DELETE FROM[/red] [blue]{tenant}[/blue].[green]{table}[/green] [red]WHERE ID IN[/red] ({followup_id_list});"


def main():
    tenant = "tenant0099"
    table = "followups"
    csv_filename = "/Users/pansel/JiraTickets/VCC-55487/python/duplicate_followups.csv"
    id_list = generate_list_of_ids_to_delete(parse_csv_file(csv_filename))
    delete_statement = build_delete_statement(tenant, table, id_list)
    print(Panel(delete_statement, title="DELETE STATEMENT", subtitle="DELETE STATEMENT"))


if __name__ == "__main__":
    main()
